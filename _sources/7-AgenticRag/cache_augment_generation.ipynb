{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a86aa13",
   "metadata": {},
   "source": [
    "### What is Cache-Augmented Generation (CAG)?\n",
    "CAG is a retrieval-free approach that bypasses the usual step of querying external knowledge sources at inference time. Instead, it preloads relevant documents into the LLM's extended context window, precomputes the model’s key‑value (KV) cache, and reuses this during inference—so the model can generate responses without additional retrieval steps "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05987315",
   "metadata": {},
   "source": [
    "In simple terms\n",
    "**Cache-Augmented Generation (CAG)** is a **retrieval-free optimization of RAG**, designed to make LLM responses faster and cheaper *without losing access to external context*.\n",
    "\n",
    "Instead of performing **retrieval queries at inference time**, CAG **pre-loads the relevant context into the model once** (before inference) and **stores the model’s internal attention state (KV cache)** so it can be reused for subsequent queries.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 Let’s unpack this step-by-step\n",
    "\n",
    "### 🧩 1. Reminder: How normal RAG works\n",
    "\n",
    "In **RAG**, every time you send a new query:\n",
    "\n",
    "1. The system searches a vector database (e.g., FAISS, Chroma, Pinecone)\n",
    "2. Retrieves top-k documents\n",
    "3. Adds them to the LLM prompt\n",
    "4. The LLM processes both the retrieved data and your question to answer.\n",
    "\n",
    "That means:\n",
    "\n",
    "* Each query repeats the **retrieval + embedding + re-encoding** cost\n",
    "* The LLM must **re-read all context tokens** every time\n",
    "* Latency grows with context length and retrieval time\n",
    "\n",
    "---\n",
    "\n",
    "### ⚡ 2. How **CAG** improves on this\n",
    "\n",
    "**Cache-Augmented Generation (CAG)** avoids redundant retrieval and re-encoding by caching the model’s *internal representation* of context.\n",
    "\n",
    "#### 🧠 Step-by-step:\n",
    "\n",
    "1. **Preload Context Once**\n",
    "\n",
    "   * Before answering questions, you feed the model all relevant background data (documents, codebase, knowledge base, etc.).\n",
    "   * The model reads and encodes these into its attention memory — the **key-value (KV) cache**.\n",
    "\n",
    "2. **Cache the KV State**\n",
    "\n",
    "   * The model’s transformer layers generate *keys and values* for every token, used during self-attention.\n",
    "   * These are stored and reused later (instead of recomputing).\n",
    "\n",
    "3. **Inference Time (Query Phase)**\n",
    "\n",
    "   * When a new question arrives, you don’t reload or re-embed the documents.\n",
    "   * You simply **reuse the cached KV states** — the model “remembers” the context instantly.\n",
    "   * The model can generate answers *as if it had already read those documents*, but without reprocessing them.\n",
    "\n",
    "✅ **No retrieval**\n",
    "✅ **No repeated encoding**\n",
    "✅ **Lower latency and cost**\n",
    "✅ **Faster multi-turn interactions**\n",
    "\n",
    "---\n",
    "\n",
    "### 🧩 3. Key Concept: KV Cache\n",
    "\n",
    "Every transformer maintains **Key–Value (KV) pairs** at each layer during attention:\n",
    "\n",
    "* **Key (K)** = representation of “what I contain”\n",
    "* **Value (V)** = representation of “what I contribute”\n",
    "* **Query (Q)** = current input’s request for relevant past info\n",
    "\n",
    "In normal generation, the LLM recomputes attention for all past tokens.\n",
    "\n",
    "In **CAG**, these KVs for the “context documents” are **precomputed and stored**, so the LLM just appends new queries to the existing attention window.\n",
    "\n",
    "Think of it like:\n",
    "\n",
    "> “The model has already read the textbook. Now it just reads the question and answers immediately — without reopening the book.”\n",
    "\n",
    "---\n",
    "\n",
    "## 🏗️ Architecture Overview\n",
    "\n",
    "```\n",
    "               ┌────────────────────────────┐\n",
    "               │  Preload Context (Offline) │\n",
    "               │   - Embed documents        │\n",
    "               │   - Run LLM once           │\n",
    "               │   - Store KV cache         │\n",
    "               └────────────┬───────────────┘\n",
    "                            │\n",
    "                            ▼\n",
    "   ┌──────────────────────────────────────────────┐\n",
    "   │             Inference / Query Time           │\n",
    "   │   - Load precomputed KV cache                │\n",
    "   │   - Inject user query                       │\n",
    "   │   - Generate answer instantly                │\n",
    "   └──────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "## 🔬 Practical Example\n",
    "\n",
    "Imagine building a **domain-specific chatbot for a law firm**:\n",
    "\n",
    "* You preload all legal documents into the LLM context (via cache).\n",
    "* During daily use, the chatbot answers new queries instantly because it reuses the **cached KV state**.\n",
    "* It doesn’t re-query a database or re-tokenize the docs each time.\n",
    "\n",
    "This is **Cache-Augmented Generation** — the model “remembers” efficiently through cache, not retrieval.\n",
    "\n",
    "---\n",
    "\n",
    "## 🚀 Benefits\n",
    "\n",
    "* **Faster inference** (no retrieval latency)\n",
    "* **Lower cost** (reuse pre-encoded context)\n",
    "* **Scalable to multi-turn sessions**\n",
    "* **More stable outputs** (no retrieval randomness)\n",
    "* **Ideal for static or semi-static corpora**\n",
    "\n",
    "---\n",
    "\n",
    "## ⚠️ Limitations\n",
    "\n",
    "* Cache must fit within the model’s **context window limit** (e.g., 128K or 1M tokens)\n",
    "* Updating cached data requires recomputing\n",
    "* Not suitable for *rapidly changing* data sources\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03e6e537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001FE4A0CC890>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001FE4A2E76E0>, root_client=<openai.OpenAI object at 0x000001FE47B3C2F0>, root_async_client=<openai.AsyncOpenAI object at 0x000001FE4A533AA0>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm=init_chat_model(\"openai:gpt-4o-mini\")\n",
    "\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12d950ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cache variable\n",
    "Model_Cache={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48802156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def cache_model(query):\n",
    "    start_time=time.time()\n",
    "    if Model_Cache.get(query):\n",
    "        print(\"**CAche Hit**\")\n",
    "        end_time=time.time()\n",
    "        elapsed_time=end_time-start_time\n",
    "        print(f\"EXECUTION TIME: {elapsed_time:.2f} seconds\")\n",
    "        return Model_Cache.get(query)\n",
    "    else:\n",
    "        print(\"***CACHE MISS – EXECUTING MODEL***\")\n",
    "        start_time = time.time()\n",
    "        response = llm.invoke(query)\n",
    "        end_time = time.time()\n",
    "        elapsed = end_time - start_time\n",
    "        print(f\"EXECUTION TIME: {elapsed:.2f} seconds\")\n",
    "        Model_Cache[query] = response\n",
    "        return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85b3c6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***CACHE MISS – EXECUTING MODEL***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXECUTION TIME: 1.73 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 8, 'total_tokens': 17, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CWNfHoEtpgz2zVwkhZv0uSgL4dqWg', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--79c60541-63fe-4007-bf1d-3a19c277428e-0', usage_metadata={'input_tokens': 8, 'output_tokens': 9, 'total_tokens': 17, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=cache_model(\"hi\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6407acf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hi': AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 8, 'total_tokens': 17, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CWNfHoEtpgz2zVwkhZv0uSgL4dqWg', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--79c60541-63fe-4007-bf1d-3a19c277428e-0', usage_metadata={'input_tokens': 8, 'output_tokens': 9, 'total_tokens': 17, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model_Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32188896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**CAche Hit**\n",
      "EXECUTION TIME: 0.00 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 8, 'total_tokens': 17, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CWNfHoEtpgz2zVwkhZv0uSgL4dqWg', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--79c60541-63fe-4007-bf1d-3a19c277428e-0', usage_metadata={'input_tokens': 8, 'output_tokens': 9, 'total_tokens': 17, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=cache_model(\"hi\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d65ff0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***CACHE MISS – EXECUTING MODEL***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXECUTION TIME: 12.08 seconds\n",
      "content=\"LangGraph is a powerful and innovative tool designed to enhance and simplify the process of natural language processing (NLP) through the application of graph theory and advanced algorithms. By leveraging the intrinsic relationships within data, LangGraph enables users to create complex linguistic structures that can be utilized across various applications, such as chatbots, sentiment analysis, and automated content generation.\\n\\nAt its core, LangGraph operates on the premise that language is inherently structured in ways that can be effectively modeled as a graph. In this representation, words and phrases are treated as nodes, while the relationships between them—such as syntactic dependencies, semantic similarities, or contextual relevance—are represented as edges. This graph-based approach allows for a richer understanding of language, as it captures nuances that traditional linear text processing methods might overlook.\\n\\nOne of the primary advantages of LangGraph is its ability to manage and analyze large datasets efficiently. In an era where data is generated at an unprecedented rate, having tools that can parse, analyze, and derive insights from massive corpuses of text is essential. LangGraph's architecture is optimized for scalability, which means it can handle multilingual datasets, varying text structures, and diverse contexts without compromising performance.\\n\\nThe versatility of LangGraph also extends to its application across different domains. In the field of educational technology, it can assist in creating personalized learning experiences by analyzing student interactions and tailoring content to individual needs. In marketing, LangGraph can help companies understand consumer sentiment through analysis of online reviews and social media conversations, thus enabling more effective branding strategies.\\n\\nMoreover, LangGraph is not just a passive analysis tool; it is equipped with machine learning capabilities that allow it to adapt and improve over time. As it processes more data, it learns from patterns and outcomes, thereby refining its predictive models. This continuous learning aspect makes LangGraph particularly valuable in dynamic fields where language and trends evolve rapidly.\\n\\nAnother significant aspect of LangGraph is its user-friendly interface, which is designed to accommodate users with varying levels of technical expertise. Whether you are a seasoned data scientist or a business professional seeking to leverage data-driven insights, LangGraph offers intuitive features that simplify complex operations. This democratization of technology ensures that organizations can harness the power of NLP without requiring extensive resources or specialized knowledge.\\n\\nThe integration capabilities of LangGraph also set it apart. It can seamlessly connect with existing data pipelines, databases, and other software tools, making it a versatile component of any tech stack. By facilitating smooth data transfers and interoperability, LangGraph ensures that insights can be quickly translated into actionable strategies.\\n\\nIn conclusion, LangGraph presents a transformative approach to natural language processing that combines the analytical rigour of graph theory with the flexibility and scalability demanded by modern data environments. Its ability to understand language as a dynamic, relational construct opens up myriad possibilities for innovation in various sectors—from education to marketing and beyond. As organizations increasingly recognize the value of data-driven decision-making, tools like LangGraph will play a pivotal role in shaping the future of how we interact with and understand language. With its advanced capabilities, user-friendly design, and adaptability, LangGraph is poised to become a cornerstone in the evolution of natural language processing technologies.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 628, 'prompt_tokens': 18, 'total_tokens': 646, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CWNfJcarYsmtV6r1jtSh0iS9U1FGa', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--5a1f8f0e-7922-461f-bf96-feb66d5ccf2c-0' usage_metadata={'input_tokens': 18, 'output_tokens': 628, 'total_tokens': 646, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "query=\"can you give me 500 words on langgraph?\"\n",
    "response =cache_model(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b37e3685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**CAche Hit**\n",
      "EXECUTION TIME: 0.00 seconds\n",
      "content=\"LangGraph is a powerful and innovative tool designed to enhance and simplify the process of natural language processing (NLP) through the application of graph theory and advanced algorithms. By leveraging the intrinsic relationships within data, LangGraph enables users to create complex linguistic structures that can be utilized across various applications, such as chatbots, sentiment analysis, and automated content generation.\\n\\nAt its core, LangGraph operates on the premise that language is inherently structured in ways that can be effectively modeled as a graph. In this representation, words and phrases are treated as nodes, while the relationships between them—such as syntactic dependencies, semantic similarities, or contextual relevance—are represented as edges. This graph-based approach allows for a richer understanding of language, as it captures nuances that traditional linear text processing methods might overlook.\\n\\nOne of the primary advantages of LangGraph is its ability to manage and analyze large datasets efficiently. In an era where data is generated at an unprecedented rate, having tools that can parse, analyze, and derive insights from massive corpuses of text is essential. LangGraph's architecture is optimized for scalability, which means it can handle multilingual datasets, varying text structures, and diverse contexts without compromising performance.\\n\\nThe versatility of LangGraph also extends to its application across different domains. In the field of educational technology, it can assist in creating personalized learning experiences by analyzing student interactions and tailoring content to individual needs. In marketing, LangGraph can help companies understand consumer sentiment through analysis of online reviews and social media conversations, thus enabling more effective branding strategies.\\n\\nMoreover, LangGraph is not just a passive analysis tool; it is equipped with machine learning capabilities that allow it to adapt and improve over time. As it processes more data, it learns from patterns and outcomes, thereby refining its predictive models. This continuous learning aspect makes LangGraph particularly valuable in dynamic fields where language and trends evolve rapidly.\\n\\nAnother significant aspect of LangGraph is its user-friendly interface, which is designed to accommodate users with varying levels of technical expertise. Whether you are a seasoned data scientist or a business professional seeking to leverage data-driven insights, LangGraph offers intuitive features that simplify complex operations. This democratization of technology ensures that organizations can harness the power of NLP without requiring extensive resources or specialized knowledge.\\n\\nThe integration capabilities of LangGraph also set it apart. It can seamlessly connect with existing data pipelines, databases, and other software tools, making it a versatile component of any tech stack. By facilitating smooth data transfers and interoperability, LangGraph ensures that insights can be quickly translated into actionable strategies.\\n\\nIn conclusion, LangGraph presents a transformative approach to natural language processing that combines the analytical rigour of graph theory with the flexibility and scalability demanded by modern data environments. Its ability to understand language as a dynamic, relational construct opens up myriad possibilities for innovation in various sectors—from education to marketing and beyond. As organizations increasingly recognize the value of data-driven decision-making, tools like LangGraph will play a pivotal role in shaping the future of how we interact with and understand language. With its advanced capabilities, user-friendly design, and adaptability, LangGraph is poised to become a cornerstone in the evolution of natural language processing technologies.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 628, 'prompt_tokens': 18, 'total_tokens': 646, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CWNfJcarYsmtV6r1jtSh0iS9U1FGa', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--5a1f8f0e-7922-461f-bf96-feb66d5ccf2c-0' usage_metadata={'input_tokens': 18, 'output_tokens': 628, 'total_tokens': 646, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "query=\"can you give me 500 words on langgraph?\"\n",
    "response =cache_model(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50bc19f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***CACHE MISS – EXECUTING MODEL***\n",
      "EXECUTION TIME: 13.57 seconds\n",
      "content='LangGraph is a state-of-the-art language modeling framework designed to enhance natural language understanding and generation by utilizing graph-based structures. It leverages the concepts of graph theory to represent linguistic data in a way that captures the complex relationships between words, phrases, and ideas. The innovation behind LangGraph lies in its ability to create a multi-dimensional representation of language, moving beyond traditional linear sequences to encapsulate contextual and semantic nuances.\\n\\nAt its core, LangGraph combines elements of graph neural networks (GNNs) with powerful transformers architectures, facilitating the integration of various linguistic modalities. This hybrid approach allows for a more sophisticated understanding of how words and sentences connect in meaningful ways. Unlike conventional models that primarily operate on sequential data, LangGraph constructs a graph where nodes represent linguistic entities (such as words or phrases), and edges represent the relationships or dependencies between them. This graph structure helps to simulate the complexities of human communication, where meaning is often derived from the interplay of multiple components rather than a single linear trajectory.\\n\\nOne of the primary advantages of LangGraph is its ability to handle various linguistic phenomena, such as polysemy, synonymy, and context dependence. By mapping words not just to their immediate neighbors but also to a broader contextual network, LangGraph can disambiguate meanings based on surrounding information. This characteristic makes it particularly valuable for applications like machine translation, sentiment analysis, and dialogue systems, where the interpretation of language can vary significantly based on context.\\n\\nMoreover, LangGraph incorporates advanced techniques such as attention mechanisms, which allow the model to focus selectively on different parts of the graph when making predictions. This attention to context ensures that the model can prioritize relevant information while filtering out noise, thus improving its performance in tasks requiring nuanced language understanding.\\n\\nThe training process for LangGraph typically involves large-scale datasets that include diverse linguistic inputs. This can encompass anything from social media posts to formal academic texts, providing the model with a rich tapestry of language use. By training on comprehensive data, LangGraph develops a deep understanding of linguistic patterns and relationships, enhancing its ability to generalize to unseen data.\\n\\nIn addition to its technical architecture, LangGraph also emphasizes usability and accessibility for developers. It comes equipped with intuitive interfaces and documentation, enabling practitioners in the fields of computational linguistics, artificial intelligence, and software development to easily implement and adapt it to their specific needs. The model is designed to integrate seamlessly with existing natural language processing (NLP) frameworks, promoting collaboration and innovation within the broader AI community.\\n\\nAs the demand for more sophisticated language processing tools continues to escalate, LangGraph stands out as a promising solution. Its graph-based approach not only aligns closely with the intricacies of human language but also opens new avenues for research and development. Future enhancements may include expanding its capabilities to incorporate multimedia elements, such as visual context or auditory cues, further enriching the model’s understanding of language in its multifaceted forms.\\n\\nIn conclusion, LangGraph represents a significant leap forward in the realm of natural language processing. By harnessing the power of graph theory and advanced neural network architectures, it provides a more nuanced and effective way of understanding and generating human language. As developers and researchers continue to explore its potential, LangGraph is poised to play a crucial role in shaping the future of AI-driven communication technologies.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 654, 'prompt_tokens': 16, 'total_tokens': 670, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CWNfVtjmk1jNPe2LYHKnUTZEN8dW6', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--d6fb435c-aac9-4003-a87d-59c9e4772612-0' usage_metadata={'input_tokens': 16, 'output_tokens': 654, 'total_tokens': 670, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "query=\"give me 500 words on langgraph?\"\n",
    "response =cache_model(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5083b6b7",
   "metadata": {},
   "source": [
    "### Advanced CAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf663496",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import TypedDict, List, Optional\n",
    "import time\n",
    "\n",
    "# ---- LangGraph / LangChain ----\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# ---- FAISS vector stores ----\n",
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bb0e1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================= CONFIG =================\n",
    "EMBED_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"  # 384-dim\n",
    "VECTOR_DIM = 384\n",
    "\n",
    "LLM_MODEL = \"gpt-4o-mini\"\n",
    "LLM_TEMPERATURE = 0\n",
    "\n",
    "RETRIEVE_TOP_K = 4\n",
    "CACHE_TOP_K = 3\n",
    "\n",
    "CACHE_DISTANCE_THRESHOLD = 0.45\n",
    "\n",
    "# Optional TTL for cache entries (seconds). 0 = disabled.\n",
    "CACHE_TTL_SEC = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "298cde63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================= STATE ==================\n",
    "class RAGState(TypedDict):\n",
    "    question: str\n",
    "    normalized_question: str\n",
    "    context_docs: List[Document]\n",
    "    answer: Optional[str]\n",
    "    citations: List[str]\n",
    "    cache_hit: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55558c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== GLOBALS ===================\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "EMBED = HuggingFaceEmbeddings(model_name=EMBED_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9791f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- QA CACHE (EMPTY, SAFE INIT) -----\n",
    "qa_index = faiss.IndexFlatL2(VECTOR_DIM)  # distance; lower is better\n",
    "QA_CACHE = FAISS(\n",
    "    embedding_function=EMBED,\n",
    "    index=qa_index,\n",
    "    docstore=InMemoryDocstore({}),\n",
    "    index_to_docstore_id={}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff36b896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x1fe2f6b7440>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QA_CACHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "080fa22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- RAG STORE (demo only) -----\n",
    "RAG_STORE = FAISS.from_texts(\n",
    "    texts=[\n",
    "        \"LangGraph lets you compose stateful LLM workflows as graphs.\",\n",
    "        \"In LangGraph, nodes can be cached; node caching memoizes outputs keyed by inputs for a TTL.\",\n",
    "        \"Retrieval-Augmented Generation (RAG) retrieves external context and injects it into prompts.\",\n",
    "        \"Semantic caching reuses prior answers when new questions are semantically similar.\"\n",
    "    ],\n",
    "    embedding=EMBED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0cc311a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM = ChatOpenAI(model=LLM_MODEL, temperature=LLM_TEMPERATURE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d43f16f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001FE7913E660>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001FE2F6B6240>, root_client=<openai.OpenAI object at 0x000001FE7913F470>, root_async_client=<openai.AsyncOpenAI object at 0x000001FE7913F3B0>, model_name='gpt-4o-mini', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "997e26d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================ NODES ===================\n",
    "def normalize_query(state: RAGState) -> RAGState:\n",
    "    q = (state[\"question\"] or \"\").strip()\n",
    "    state[\"normalized_question\"] = q.lower()\n",
    "    return state\n",
    "\n",
    "def semantic_cache_lookup(state: RAGState) -> RAGState:\n",
    "    q = state[\"normalized_question\"]\n",
    "    state[\"cache_hit\"] = False  # default\n",
    "\n",
    "    if not q:\n",
    "        return state\n",
    "\n",
    "    # ✅ Guard: FAISS crashes if ntotal == 0 and you ask for k>0\n",
    "    if getattr(QA_CACHE, \"index\", None) is None or QA_CACHE.index.ntotal == 0:\n",
    "        return state\n",
    "\n",
    "    # For FAISS L2 wrapper, this returns (Document, distance) with lower=better\n",
    "    hits = QA_CACHE.similarity_search_with_score(q, k=CACHE_TOP_K)\n",
    "    if not hits:\n",
    "        return state\n",
    "\n",
    "    best_doc, dist = hits[0]\n",
    "\n",
    "    # Optional TTL\n",
    "    if CACHE_TTL_SEC > 0:\n",
    "        ts = best_doc.metadata.get(\"ts\")\n",
    "        if ts is None or (time.time() - float(ts)) > CACHE_TTL_SEC:\n",
    "            return state\n",
    "\n",
    "    # L2 distance gate (lower = more similar)\n",
    "    if dist <= CACHE_DISTANCE_THRESHOLD:\n",
    "        cached_answer = best_doc.metadata.get(\"answer\")\n",
    "        if cached_answer:\n",
    "            state[\"answer\"] = cached_answer\n",
    "            state[\"citations\"] = [\"(cache)\"]\n",
    "            state[\"cache_hit\"] = True\n",
    "\n",
    "    return state\n",
    "\n",
    "def respond_from_cache(state: RAGState) -> RAGState:\n",
    "    return state\n",
    "\n",
    "def retrieve(state: RAGState) -> RAGState:\n",
    "    q = state[\"normalized_question\"]\n",
    "    docs = RAG_STORE.similarity_search(q, k=RETRIEVE_TOP_K)\n",
    "    state[\"context_docs\"] = docs\n",
    "    return state\n",
    "\n",
    "def generate(state: RAGState) -> RAGState:\n",
    "    q = state[\"question\"]\n",
    "    docs = state.get(\"context_docs\", [])\n",
    "    ctx = \"\\n\\n\".join([f\"[doc-{i}] {d.page_content}\" for i, d in enumerate(docs, start=1)])\n",
    "\n",
    "    system = (\n",
    "        \"You are a precise RAG assistant. Use the context when helpful. \"\n",
    "        \"Cite with [doc-i] markers if you use a fact from the context.\"\n",
    "    )\n",
    "    user = f\"Question: {q}\\n\\nContext:\\n{ctx}\\n\\nWrite a concise answer with citations.\"\n",
    "\n",
    "    resp = LLM.invoke([{\"role\": \"system\", \"content\": system},\n",
    "                       {\"role\": \"user\", \"content\": user}])\n",
    "    state[\"answer\"] = resp.content\n",
    "    state[\"citations\"] = [f\"[doc-{i}]\" for i in range(1, len(docs) + 1)]\n",
    "    return state\n",
    "\n",
    "def cache_write(state: RAGState) -> RAGState:\n",
    "    q = state[\"normalized_question\"]\n",
    "    a = state.get(\"answer\")\n",
    "    if not q or not a:\n",
    "        return state\n",
    "\n",
    "    QA_CACHE.add_texts(\n",
    "        texts=[q],\n",
    "        metadatas=[{\n",
    "            \"answer\": a,\n",
    "            \"ts\": time.time(),\n",
    "        }]\n",
    "    )\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "462f44af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x000001FE2EDF2870>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============== GRAPH WIRING ==============\n",
    "graph = StateGraph(RAGState)\n",
    "\n",
    "graph.add_node(\"normalize_query\", normalize_query)\n",
    "graph.add_node(\"semantic_cache_lookup\", semantic_cache_lookup)\n",
    "graph.add_node(\"respond_from_cache\", respond_from_cache)\n",
    "graph.add_node(\"retrieve\", retrieve)\n",
    "graph.add_node(\"generate\", generate)\n",
    "graph.add_node(\"cache_write\", cache_write)\n",
    "\n",
    "graph.set_entry_point(\"normalize_query\")\n",
    "graph.add_edge(\"normalize_query\", \"semantic_cache_lookup\")\n",
    "\n",
    "def _branch(state: RAGState) -> str:\n",
    "    return \"respond_from_cache\" if state.get(\"cache_hit\") else \"retrieve\"\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"semantic_cache_lookup\",\n",
    "    _branch,\n",
    "    {\n",
    "        \"respond_from_cache\": \"respond_from_cache\",\n",
    "        \"retrieve\": \"retrieve\"\n",
    "    }\n",
    ")\n",
    "\n",
    "graph.add_edge(\"respond_from_cache\", END)\n",
    "graph.add_edge(\"retrieve\", \"generate\")\n",
    "graph.add_edge(\"generate\", \"cache_write\")\n",
    "graph.add_edge(\"cache_write\", END)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = graph.compile(checkpointer=memory)\n",
    "app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba9bde2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: LangGraph is a framework that allows users to compose stateful workflows for large language models (LLMs) in the form of graphs, enabling the management of complex interactions and data flows [doc-2]. It also features node caching, which memoizes outputs based on inputs for a specified time-to-live (TTL) [doc-1].\n",
      "Citations: ['[doc-1]', '[doc-2]', '[doc-3]', '[doc-4]']\n",
      "Cache hit?: False\n"
     ]
    }
   ],
   "source": [
    "# ================= DEMO ===================\n",
    "if __name__ == \"__main__\":\n",
    "    thread_cfg = {\"configurable\": {\"thread_id\": \"demo-user-1\"}}\n",
    "\n",
    "    q1 = \"What is LangGraph ?\"\n",
    "    out1 = app.invoke({\"question\": q1, \"context_docs\": [], \"citations\": []}, thread_cfg)\n",
    "    print(\"Answer:\", out1[\"answer\"])\n",
    "    print(\"Citations:\", out1.get(\"citations\"))\n",
    "    print(\"Cache hit?:\", out1.get(\"cache_hit\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2039bde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: LangGraph is a framework that allows users to compose stateful workflows for large language models (LLMs) in the form of graphs, enabling the management of complex interactions and data flows [doc-2]. It also features node caching, which memoizes outputs based on inputs for a specified time-to-live (TTL) [doc-1].\n",
      "Citations: ['(cache)']\n",
      "Cache hit?: True\n"
     ]
    }
   ],
   "source": [
    "q1 = \"Explain about LangGraph ?\"\n",
    "out1 = app.invoke({\"question\": q1, \"context_docs\": [], \"citations\": []}, thread_cfg)\n",
    "print(\"Answer:\", out1[\"answer\"])\n",
    "print(\"Citations:\", out1.get(\"citations\"))\n",
    "print(\"Cache hit?:\", out1.get(\"cache_hit\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c8d9021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: LangGraph agents are part of a framework that allows users to compose stateful workflows using large language models (LLMs) structured as graphs [doc-2]. These agents can utilize features like node caching, which memoizes outputs based on inputs for a specified time-to-live (TTL) [doc-1]. Additionally, they can leverage semantic caching to reuse previous answers when new questions are semantically similar, enhancing efficiency [doc-4]. This approach aligns with Retrieval-Augmented Generation (RAG), which retrieves external context to enrich prompts [doc-3].\n",
      "Citations: ['[doc-1]', '[doc-2]', '[doc-3]', '[doc-4]']\n",
      "Cache hit?: False\n"
     ]
    }
   ],
   "source": [
    "q1 = \"Explain about LangGraph agents ?\"\n",
    "out1 = app.invoke({\"question\": q1, \"context_docs\": [], \"citations\": []}, thread_cfg)\n",
    "print(\"Answer:\", out1[\"answer\"])\n",
    "print(\"Citations:\", out1.get(\"citations\"))\n",
    "print(\"Cache hit?:\", out1.get(\"cache_hit\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d890c065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: LangGraph agents are part of a framework that allows users to compose stateful workflows using large language models (LLMs) structured as graphs [doc-2]. These agents can utilize features like node caching, which memoizes outputs based on inputs for a specified time-to-live (TTL) [doc-1]. Additionally, they can leverage semantic caching to reuse previous answers when new questions are semantically similar, enhancing efficiency [doc-4]. This approach aligns with Retrieval-Augmented Generation (RAG), which retrieves external context to enrich prompts [doc-3].\n",
      "Citations: ['(cache)']\n",
      "Cache hit?: True\n"
     ]
    }
   ],
   "source": [
    "q1 = \"Explain about agents in Langgraph ?\"\n",
    "out1 = app.invoke({\"question\": q1, \"context_docs\": [], \"citations\": []}, thread_cfg)\n",
    "print(\"Answer:\", out1[\"answer\"])\n",
    "print(\"Citations:\", out1.get(\"citations\"))\n",
    "print(\"Cache hit?:\", out1.get(\"cache_hit\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0029eefe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0ca872",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
