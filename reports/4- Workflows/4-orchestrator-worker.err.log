Traceback (most recent call last):
  File "C:\Users\Welcome\OneDrive\Documents\AI\AgenticAi\venv\Lib\site-packages\jupyter_cache\executors\utils.py", line 58, in single_nb_execution
    executenb(
  File "C:\Users\Welcome\OneDrive\Documents\AI\AgenticAi\venv\Lib\site-packages\nbclient\client.py", line 1319, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Welcome\OneDrive\Documents\AI\AgenticAi\venv\Lib\site-packages\jupyter_core\utils\__init__.py", line 165, in wrapped
    return loop.run_until_complete(inner)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Welcome\OneDrive\Documents\AI\AgenticAi\venv\Lib\asyncio\base_events.py", line 664, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "C:\Users\Welcome\OneDrive\Documents\AI\AgenticAi\venv\Lib\site-packages\nbclient\client.py", line 709, in async_execute
    await self.async_execute_cell(
  File "C:\Users\Welcome\OneDrive\Documents\AI\AgenticAi\venv\Lib\site-packages\nbclient\client.py", line 1062, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "C:\Users\Welcome\OneDrive\Documents\AI\AgenticAi\venv\Lib\site-packages\nbclient\client.py", line 918, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
# Invoke
state = orchestrator_worker.invoke({"topic": "Create a report on Agentic AI RAGs"})

from IPython.display import Markdown
Markdown(state["final_report"])
------------------

----- stdout -----
Report Sections: sections=[Section(name='Executive Summary', description='A concise overview of the report, highlighting the purpose, key findings, and recommendations regarding Agentic AI Retrieval-Augmented Generation (RAG) systems.'), Section(name='Introduction to Agentic AI and RAG', description='Defines Agentic AI, explains the concept of Retrievalâ€‘Augmented Generation, and describes why combining them is significant for modern AI applications.'), Section(name='Architectural Foundations', description='Detailed examination of the core componentsâ€”LLM, retriever, knowledge base, and agent controllerâ€”and how they interact in an Agentic AI RAG pipeline.'), Section(name='Core Capabilities and Useâ€‘Cases', description='Explores practical scenarios such as autonomous research assistants, dynamic customer support, realâ€‘time data analytics, and knowledgeâ€‘driven decision making.'), Section(name='Agentic Decisionâ€‘Making & Planning', description='Covers how agents plan, prioritize, and execute multiâ€‘step tasks using retrieved information, including prompting strategies, tool use, and looped reasoning.'), Section(name='Knowledge Sources & Retrieval Strategies', description='Analyzes types of external knowledge (documents, databases, APIs, web), retrieval techniques (sparse vs dense, hybrid, reranking), and freshness/consistency considerations.'), Section(name='Learning & Adaptation', description='Discusses continual learning, feedback loops, reinforcement learning from human feedback (RLHF), and selfâ€‘supervision that enable agents to improve over time.'), Section(name='Safety, Trustworthiness, and Hallucination Mitigation', description='Examines methods to reduce hallucinations, enforce factuality, handle bias, and implement guardrails such as verification modules and policy engines.'), Section(name='Evaluation Frameworks', description='Presents metrics and benchmark suites for measuring relevance, accuracy, reasoning depth, latency, and cost in Agentic AI RAG systems.'), Section(name='Scalability, Performance, and Cost Optimization', description='Covers architectural scaling patterns, caching, batching, quantization, and costâ€‘aware retrieval to enable productionâ€‘grade deployments.'), Section(name='Implementation Toolkits & Platforms', description='Reviews openâ€‘source frameworks (LangChain, LlamaIndex, Haystack), cloud services (Azure AI Search, AWS Kendra, Google Vertex AI), and example code snippets.'), Section(name='Case Studies', description='Realâ€‘world examples from enterprises, research labs, and startups that have deployed Agentic AI RAG solutions, highlighting challenges and outcomes.'), Section(name='Future Directions & Research Opportunities', description='Identifies emerging trends such as multimodal retrieval, selfâ€‘hosting knowledge graphs, autonomous tool use, and regulatory considerations.'), Section(name='Conclusion & Recommendations', description='Summarizes the key takeaways and provides actionable recommendations for organizations looking to adopt Agentic AI RAG technology.'), Section(name='References', description='Citations of academic papers, technical blogs, standards, and product documentation referenced throughout the report.')]
------------------

[31m---------------------------------------------------------------------------[39m
[31mRateLimitError[39m                            Traceback (most recent call last)
[36mCell[39m[36m [39m[32mIn[7][39m[32m, line 2[39m
[32m      1[39m [38;5;66;03m# Invoke[39;00m
[32m----> [39m[32m2[39m state = [43morchestrator_worker[49m[43m.[49m[43minvoke[49m[43m([49m[43m{[49m[33;43m"[39;49m[33;43mtopic[39;49m[33;43m"[39;49m[43m:[49m[43m [49m[33;43m"[39;49m[33;43mCreate a report on Agentic AI RAGs[39;49m[33;43m"[39;49m[43m}[49m[43m)[49m
[32m      4[39m [38;5;28;01mfrom[39;00m[38;5;250m [39m[34;01mIPython[39;00m[34;01m.[39;00m[34;01mdisplay[39;00m[38;5;250m [39m[38;5;28;01mimport[39;00m Markdown
[32m      5[39m Markdown(state[[33m"[39m[33mfinal_report[39m[33m"[39m])

[36mFile [39m[32m~\OneDrive\Documents\AI\AgenticAi\venv\Lib\site-packages\langgraph\pregel\main.py:3094[39m, in [36mPregel.invoke[39m[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)[39m
[32m   3091[39m chunks: [38;5;28mlist[39m[[38;5;28mdict[39m[[38;5;28mstr[39m, Any] | Any] = []
[32m   3092[39m interrupts: [38;5;28mlist[39m[Interrupt] = []
[32m-> [39m[32m3094[39m [43m[49m[38;5;28;43;01mfor[39;49;00m[43m [49m[43mchunk[49m[43m [49m[38;5;129;43;01min[39;49;00m[43m [49m[38;5;28;43mself[39;49m[43m.[49m[43mstream[49m[43m([49m
[32m   3095[39m [43m    [49m[38;5;28;43minput[39;49m[43m,[49m
[32m   3096[39m [43m    [49m[43mconfig[49m[43m,[49m
[32m   3097[39m [43m    [49m[43mcontext[49m[43m=[49m[43mcontext[49m[43m,[49m
[32m   3098[39m [43m    [49m[43mstream_mode[49m[43m=[49m[43m[[49m[33;43m"[39;49m[33;43mupdates[39;49m[33;43m"[39;49m[43m,[49m[43m [49m[33;43m"[39;49m[33;43mvalues[39;49m[33;43m"[39;49m[43m][49m
[32m   3099[39m [43m    [49m[38;5;28;43;01mif[39;49;00m[43m [49m[43mstream_mode[49m[43m [49m[43m==[49m[43m [49m[33;43m"[39;49m[33;43mvalues[39;49m[33;43m"[39;49m
[32m   3100[39m [43m    [49m[38;5;28;43;01melse[39;49;00m[43m [49m[43mstream_mode[49m[43m,[49m
[32m   3101[39m [43m    [49m[43mprint_mode[49m[43m=[49m[43mprint_mode[49m[43m,[49m
[32m   3102[39m [43m    [49m[43moutput_keys[49m[43m=[49m[43moutput_keys[49m[43m,[49m
[32m   3103[39m [43m    [49m[43minterrupt_before[49m[43m=[49m[43minterrupt_before[49m[43m,[49m
[32m   3104[39m [43m    [49m[43minterrupt_after[49m[43m=[49m[43minterrupt_after[49m[43m,[49m
[32m   3105[39m [43m    [49m[43mdurability[49m[43m=[49m[43mdurability[49m[43m,[49m
[32m   3106[39m [43m    [49m[43m*[49m[43m*[49m[43mkwargs[49m[43m,[49m
[32m   3107[39m [43m[49m[43m)[49m[43m:[49m
[32m   3108[39m [43m    [49m[38;5;28;43;01mif[39;49;00m[43m [49m[43mstream_mode[49m[43m [49m[43m==[49m[43m [49m[33;43m"[39;49m[33;43mvalues[39;49m[33;43m"[39;49m[43m:[49m
[32m   3109[39m [43m        [49m[38;5;28;43;01mif[39;49;00m[43m [49m[38;5;28;43mlen[39;49m[43m([49m[43mchunk[49m[43m)[49m[43m [49m[43m==[49m[43m [49m[32;43m2[39;49m[43m:[49m

[36mFile [39m[32m~\OneDrive\Documents\AI\AgenticAi\venv\Lib\site-packages\langgraph\pregel\main.py:2679[39m, in [36mPregel.stream[39m[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)[39m
[32m   2677[39m [38;5;28;01mfor[39;00m task [38;5;129;01min[39;00m loop.match_cached_writes():
[32m   2678[39m     loop.output_writes(task.id, task.writes, cached=[38;5;28;01mTrue[39;00m)
[32m-> [39m[32m2679[39m [43m[49m[38;5;28;43;01mfor[39;49;00m[43m [49m[43m_[49m[43m [49m[38;5;129;43;01min[39;49;00m[43m [49m[43mrunner[49m[43m.[49m[43mtick[49m[43m([49m
[32m   2680[39m [43m    [49m[43m[[49m[43mt[49m[43m [49m[38;5;28;43;01mfor[39;49;00m[43m [49m[43mt[49m[43m [49m[38;5;129;43;01min[39;49;00m[43m [49m[43mloop[49m[43m.[49m[43mtasks[49m[43m.[49m[43mvalues[49m[43m([49m[43m)[49m[43m [49m[38;5;28;43;01mif[39;49;00m[43m [49m[38;5;129;43;01mnot[39;49;00m[43m [49m[43mt[49m[43m.[49m[43mwrites[49m[43m][49m[43m,[49m
[32m   2681[39m [43m    [49m[43mtimeout[49m[43m=[49m[38;5;28;43mself[39;49m[43m.[49m[43mstep_timeout[49m[43m,[49m
[32m   2682[39m [43m    [49m[43mget_waiter[49m[43m=[49m[43mget_waiter[49m[43m,[49m
[32m   2683[39m [43m    [49m[43mschedule_task[49m[43m=[49m[43mloop[49m[43m.[49m[43maccept_push[49m[43m,[49m
[32m   2684[39m [43m[49m[43m)[49m[43m:[49m
[32m   2685[39m [43m    [49m[38;5;66;43;03m# emit output[39;49;00m
[32m   2686[39m [43m    [49m[38;5;28;43;01myield from[39;49;00m[43m [49m[43m_output[49m[43m([49m
[32m   2687[39m [43m        [49m[43mstream_mode[49m[43m,[49m[43m [49m[43mprint_mode[49m[43m,[49m[43m [49m[43msubgraphs[49m[43m,[49m[43m [49m[43mstream[49m[43m.[49m[43mget[49m[43m,[49m[43m [49m[43mqueue[49m[43m.[49m[43mEmpty[49m
[32m   2688[39m [43m    [49m[43m)[49m
[32m   2689[39m loop.after_tick()

[36mFile [39m[32m~\OneDrive\Documents\AI\AgenticAi\venv\Lib\site-packages\langgraph\pregel\_runner.py:258[39m, in [36mPregelRunner.tick[39m[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)[39m
[32m    256[39m [38;5;66;03m# panic on failure or timeout[39;00m
[32m    257[39m [38;5;28;01mtry[39;00m:
[32m--> [39m[32m258[39m     [43m_panic_or_proceed[49m[43m([49m
[32m    259[39m [43m        [49m[43mfutures[49m[43m.[49m[43mdone[49m[43m.[49m[43munion[49m[43m([49m[43mf[49m[43m [49m[38;5;28;43;01mfor[39;49;00m[43m [49m[43mf[49m[43m,[49m[43m [49m[43mt[49m[43m [49m[38;5;129;43;01min[39;49;00m[43m [49m[43mfutures[49m[43m.[49m[43mitems[49m[43m([49m[43m)[49m[43m [49m[38;5;28;43;01mif[39;49;00m[43m [49m[43mt[49m[43m [49m[38;5;129;43;01mis[39;49;00m[43m [49m[38;5;129;43;01mnot[39;49;00m[43m [49m[38;5;28;43;01mNone[39;49;00m[43m)[49m[43m,[49m
[32m    260[39m [43m        [49m[43mpanic[49m[43m=[49m[43mreraise[49m[43m,[49m
[32m    261[39m [43m    [49m[43m)[49m
[32m    262[39m [38;5;28;01mexcept[39;00m [38;5;167;01mException[39;00m [38;5;28;01mas[39;00m exc:
[32m    263[39m     [38;5;28;01mif[39;00m tb := exc.__traceback__:

[36mFile [39m[32m~\OneDrive\Documents\AI\AgenticAi\venv\Lib\site-packages\langgraph\pregel\_runner.py:520[39m, in [36m_panic_or_proceed[39m[34m(futs, timeout_exc_cls, panic)[39m
[32m    518[39m                 interrupts.append(exc)
[32m    519[39m             [38;5;28;01melif[39;00m fut [38;5;129;01mnot[39;00m [38;5;129;01min[39;00m SKIP_RERAISE_SET:
[32m--> [39m[32m520[39m                 [38;5;28;01mraise[39;00m exc
[32m    521[39m [38;5;66;03m# raise combined interrupts[39;00m
[32m    522[39m [38;5;28;01mif[39;00m interrupts:

[36mFile [39m[32m~\OneDrive\Documents\AI\AgenticAi\venv\Lib\site-packages\langgraph\pregel\_executor.py:80[39m, in [36mBackgroundExecutor.done[39m[34m(self, task)[39m
[32m     78[39m [38;5;250m[39m[33;03m"""Remove the task from the tasks dict when it's done."""[39;00m
[32m     79[39m [38;5;28;01mtry[39;00m:
[32m---> [39m[32m80[39m     [43mtask[49m[43m.[49m[43mresult[49m[43m([49m[43m)[49m
[32m     81[39m [38;5;28;01mexcept[39;00m GraphBubbleUp:
[32m     82[39m     [38;5;66;03m# This exception is an interruption signal, not an error[39;00m
[32m     83[39m     [38;5;66;03m# so we don't want to re-raise it on exit[39;00m
[32m     84[39m     [38;5;28mself[39m.tasks.pop(task)

[36mFile [39m[32m~\OneDrive\Documents\AI\AgenticAi\venv\Lib\concurrent\futures\_base.py:449[39m, in [36mFuture.result[39m[34m(self, timeout)[39m
[32m    447[39m     [38;5;28;01mraise[39;00m CancelledError()
[32m    448[39m [38;5;28;01melif[39;00m [38;5;28mself[39m._state == FINISHED:
[32m--> [39m[32m449[39m     [38;5;28;01mreturn[39;00m [38;5;28;43mself[39;49m[43m.[49m[43m__get_result[49m[43m([49m[43m)[49m
[32m    451[39m [38;5;28mself[39m._condition.wait(timeout)
[32m    453[39m [38;5;28;01mif[39;00m [38;5;28mself[39m._state [38;5;129;01min[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:

[36mFile [39m[32m~\OneDrive\Documents\AI\AgenticAi\venv\Lib\concurrent\futures\_base.py:401[39m, in [36mFuture.__get_result[39m[34m(self)[39m
[32m    399[39m [38;5;28;01mif[39;00m [38;5;28mself[39m._exception:
[32m    400[39m     [38;5;28;01mtry[39;00m:
[32m--> [39m[32m401[39m         [38;5;28;01mraise[39;00m [38;5;28mself[39m._exception
[32m    402[39m     [38;5;28;01mfinally[39;00m:
[32m    403[39m         [38;5;66;03m# Break a reference cycle with the exception in self._exception[39;00m
[32m    404[39m         [38;5;28mself[39m = [38;5;28;01mNone[39;00m

[36mFile [39m[32m~\OneDrive\Documents\AI\AgenticAi\venv\Lib\concurrent\futures\thread.py:58[39m, in [36m_WorkItem.run[39m[34m(self)[39m
[32m     55[39m     [38;5;28;01mreturn[39;00m
[32m     57[39m [38;5;28;01mtry[39;00m:
[32m---> [39m[32m58[39m     result = [38;5;28;43mself[39;49m[43m.[49m[43mfn[49m[43m([49m[43m*[49m[38;5;28;43mself[39;49m[43m.[49m[43margs[49m[43m,[49m[43m [49m[43m*[49m[43m*[49m[38;5;28;43mself[39;49m[43m.[49m[43mkwargs[49m[43m)[49m
[32m     59[39m [38;5;28;01mexcept[39;00m [38;5;167;01mBaseException[39;00m [38;5;28;01mas[39;00m exc:
[32m     60[39m     [38;5;28mself[39m.future.set_exception(exc)

[36mFile [39m[32m~\OneDrive\Documents\AI\AgenticAi\venv\Lib\site-packages\langgraph\pregel\_retry.py:42[39m, in [36mrun_with_retry[39m[34m(task, retry_policy, configurable)[39m
[32m     40[39m     task.writes.clear()
[32m     41[39m     [38;5;66;03m# run the task[39;00m
[32m---> [39m[32m42[39m     [38;5;28;01mreturn[39;00m [43mtask[49m[43m.[49m[43mproc[49m[43m.[49m[43minvoke[49m[43m([49m[43mtask[49m[43m.[49m[43minput[49m[43m,[49m[43m [49m[43mconfig[49m[43m)[49m
[32m     43[39m [38;5;28;01mexcept[39;00m ParentCommand [38;5;28;01mas[39;00m exc:
[32m     44[39m     ns: [38;5;28mstr[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]

[36mFile [39m[32m~\OneDrive\Documents\AI\AgenticAi\venv\Lib\site-packages\langgraph\_internal\_runnable.py:656[39m, in [36mRunnableSeq.invoke[39m[34m(self, input, config, **kwargs)[39m
[32m    654[39m     [38;5;66;03m# run in context[39;00m
[32m    655[39m     [38;5;28;01mwith[39;00m set_config_context(config, run) [38;5;28;01mas[39;00m context:
[32m--> [39m[32m656[39m         [38;5;28minput[39m = [43mcontext[49m[43m.[49m[43mrun[49m[43m([49m[43mstep[49m[43m.[49m[43minvoke[49m[43m,[49m[43m [49m[38;5;28;43minput[39;49m[43m,[49m[43m [49m[43mconfig[49m[43m,[49m[43m [49m[43m*[49m[43m*[49m[43mkwargs[49m[43m)[49m
[32m    657[39m [38;5;28;01melse[39;00m:
[32m    658[39m     [38;5;28minput[39m = step.invoke([38;5;28minput[39m, config)

[36mFile [39m[32m~\OneDrive\Documents\AI\AgenticAi\venv\Lib\site-packages\langgraph\_internal\_runnable.py:400[39m, in [36mRunnableCallable.invoke[39m[34m(self, input, config, **kwargs)[39m
[32m    398[39m         run_manager.on_chain_end(ret)
[32m    399[39m [38;5;28;01melse[39;00m:
[32m--> [39m[32m400[39m     ret = [38;5;28;43mself[39;49m[43m.[49m[43mfunc[49m[43m([49m[43m*[49m[43margs[49m[43m,[49m[43m [49m[43m*[49m[43m*[49m[43mkwargs[49m[43m)[49m
[32m    401[39m [38;5;28;01mif[39;00m [38;5;28mself[39m.recurse [38;5;129;01mand[39;00m [38;5;28misinstance[39m(ret, Runnable):
[32m    402[39m     [38;5;28;01mreturn[39;00m ret.invoke([38;5;28minput[39m, config)

[36mCell[39m[36m [39m[32mIn[5][39m[32m, line 21[39m, in [36mllm_call[39m[34m(state)[39m
[32m     18[39m [38;5;250m[39m[33;03m"""Worker writes a section of the report"""[39;00m
[32m     20[39m [38;5;66;03m# Generate section[39;00m
[32m---> [39m[32m21[39m section = [43mllm[49m[43m.[49m[43minvoke[49m[43m([49m
[32m     22[39m [43m    [49m[43m[[49m
[32m     23[39m [43m        [49m[43mSystemMessage[49m[43m([49m
[32m     24[39m [43m            [49m[43mcontent[49m[43m=[49m[33;43m"[39;49m[33;43mWrite a report section following the provided name and description. Include no preamble for each section. Use markdown formatting.[39;49m[33;43m"[39;49m
[32m     25[39m [43m        [49m[43m)[49m[43m,[49m
[32m     26[39m [43m        [49m[43mHumanMessage[49m[43m([49m
[32m     27[39m [43m            [49m[43mcontent[49m[43m=[49m[33;43mf[39;49m[33;43m"[39;49m[33;43mHere is the section name: [39;49m[38;5;132;43;01m{[39;49;00m[43mstate[49m[43m[[49m[33;43m'[39;49m[33;43msection[39;49m[33;43m'[39;49m[43m][49m[43m.[49m[43mname[49m[38;5;132;43;01m}[39;49;00m[33;43m and description: [39;49m[38;5;132;43;01m{[39;49;00m[43mstate[49m[43m[[49m[33;43m'[39;49m[33;43msection[39;49m[33;43m'[39;49m[43m][49m[43m.[49m[43mdescription[49m[38;5;132;43;01m}[39;49;00m[33;43m"[39;49m
[32m     28[39m [43m        [49m[43m)[49m[43m,[49m
[32m     29[39m [43m    [49m[43m][49m
[32m     30[39m [43m[49m[43m)[49m
[32m     32[39m [38;5;66;03m# Write the updated section to completed sections[39;00m
[32m     33[39m [38;5;28;01mreturn[39;00m {[33m"[39m[33mcompleted_sections[39m[33m"[39m: [section.content]}

[36mFile [39m[32m~\OneDrive\Documents\AI\AgenticAi\venv\Lib\site-packages\langchain_core\language_models\chat_models.py:379[39m, in [36mBaseChatModel.invoke[39m[34m(self, input, config, stop, **kwargs)[39m
[32m    365[39m [38;5;129m@override[39m
[32m    366[39m [38;5;28;01mdef[39;00m[38;5;250m [39m[34minvoke[39m(
[32m    367[39m     [38;5;28mself[39m,
[32m   (...)[39m[32m    372[39m     **kwargs: Any,
[32m    373[39m ) -> AIMessage:
[32m    374[39m     config = ensure_config(config)
[32m    375[39m     [38;5;28;01mreturn[39;00m cast(
[32m    376[39m         [33m"[39m[33mAIMessage[39m[33m"[39m,
[32m    377[39m         cast(
[32m    378[39m             [33m"[39m[33mChatGeneration[39m[33m"[39m,
[32m--> [39m[32m379[39m             [38;5;28;43mself[39;49m[43m.[49m[43mgenerate_prompt[49m[43m([49m
[32m    380[39m [43m                [49m[43m[[49m[38;5;28;43mself[39;49m[43m.[49m[43m_convert_input[49m[43m([49m[38;5;28;43minput[39;49m[43m)[49m[43m][49m[43m,[49m
[32m    381[39m [43m                [49m[43mstop[49m[43m=[49m[43mstop[49m[43m,[49m
[32m    382[39m [43m                [49m[43mcallbacks[49m[43m=[49m[43mconfig[49m[43m.[49m[43mget[49m[43m([49m[33;43m"[39;49m[33;43mcallbacks[39;49m[33;43m"[39;49m[43m)[49m[43m,[49m
[32m    383[39m [43m                [49m[43mtags[49m[43m=[49m[43mconfig[49m[43m.[49m[43mget[49m[43m([49m[33;43m"[39;49m[33;43mtags[39;49m[33;43m"[39;49m[43m)[49m[43m,[49m
[32m    384[39m [43m                [49m[43mmetadata[49m[43m=[49m[43mconfig[49m[43m.[49m[43mget[49m[43m([49m[33;43m"[39;49m[33;43mmetadata[39;49m[33;43m"[39;49m[43m)[49m[43m,[49m
[32m    385[39m [43m                [49m[43mrun_name[49m[43m=[49m[43mconfig[49m[43m.[49m[43mget[49m[43m([49m[33;43m"[39;49m[33;43mrun_name[39;49m[33;43m"[39;49m[43m)[49m[43m,[49m
[32m    386[39m [43m                [49m[43mrun_id[49m[43m=[49m[43mconfig[49m[43m.[49m[43mpop[49m[43m([49m[33;43m"[39;49m[33;43mrun_id[39;49m[33;43m"[39;49m[43m,[49m[43m [49m[38;5;28;43;01mNone[39;49;00m[43m)[49m[43m,[49m
[32m    387[39m [43m                [49m[43m*[49m[43m*[49m[43mkwargs[49m[43m,[49m
[32m    388[39m [43m            [49m[43m)[49m.generations[[32m0[39m][[32m0[39m],
[32m    389[39m         ).message,
[32m    390[39m     )

[36mFile [39m[32m~\OneDrive\Documents\AI\AgenticAi\venv\Lib\site-packages\langchain_core\language_models\chat_models.py:1088[39m, in [36mBaseChatModel.generate_prompt[39m[34m(self, prompts, stop, callbacks, **kwargs)[39m
[32m   1079[39m [38;5;129m@override[39m
[32m   1080[39m [38;5;28;01mdef[39;00m[38;5;250m [39m[34mgenerate_prompt[39m(
[32m   1081[39m     [38;5;28mself[39m,
[32m   (...)[39m[32m   1085[39m     **kwargs: Any,
[32m   1086[39m ) -> LLMResult:
[32m   1087[39m     prompt_messages = [p.to_messages() [38;5;28;01mfor[39;00m p [38;5;129;01min[39;00m prompts]
[32m-> [39m[32m1088[39m     [38;5;28;01mreturn[39;00m [38;5;28;43mself[39;49m[43m.[49m[43mgenerate[49m[43m([49m[43mprompt_messages[49m[43m,[49m[43m [49m[43mstop[49m[43m=[49m[43mstop[49m[43m,[49m[43m [49m[43mcallbacks[49m[43m=[49m[43mcallbacks[49m[43m,[49m[43m [49m[43m*[49m[43m*[49m[43mkwargs[49m[43m)[49m

[36mFile [39m[32m~\OneDrive\Documents\AI\AgenticAi\venv\Lib\site-packages\langchain_core\language_models\chat_models.py:903[39m, in [36mBaseChatModel.generate[39m[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)[39m
[32m    900[39m [38;5;28;01mfor[39;00m i, m [38;5;129;01min[39;00m [38;5;28menumerate[39m(input_messages):
[32m    901[39m     [38;5;28;01mtry[39;00m:
[32m    902[39m         results.append(
[32m--> [39m[32m903[39m             [38;5;28;43mself[39;49m[43m.[49m[43m_generate_with_cache[49m[43m([49m
[32m    904[39m [43m                [49m[43mm[49m[43m,[49m
[32m    905[39m [43m                [49m[43mstop[49m[43m=[49m[43mstop[49m[43m,[49m
[32m    906[39m [43m                [49m[43mrun_manager[49m[43m=[49m[43mrun_managers[49m[43m[[49m[43mi[49m[43m][49m[43m [49m[38;5;28;43;01mif[39;49;00m[43m [49m[43mrun_managers[49m[43m [49m[38;5;28;43;01melse[39;49;00m[43m [49m[38;5;28;43;01mNone[39;49;00m[43m,[49m
[32m    907[39m [43m                [49m[43m*[49m[43m*[49m[43mkwargs[49m[43m,[49m
[32m    908[39m [43m            [49m[43m)[49m
[32m    909[39m         )
[32m    910[39m     [38;5;28;01mexcept[39;00m [38;5;167;01mBaseException[39;00m [38;5;28;01mas[39;00m e:
[32m    911[39m         [38;5;28;01mif[39;00m run_managers:

[36mFile [39m[32m~\OneDrive\Documents\AI\AgenticAi\venv\Lib\site-packages\langchain_core\language_models\chat_models.py:1192[39m, in [36mBaseChatModel._generate_with_cache[39m[34m(self, messages, stop, run_manager, **kwargs)[39m
[32m   1190[39m     result = generate_from_stream([38;5;28miter[39m(chunks))
[32m   1191[39m [38;5;28;01melif[39;00m inspect.signature([38;5;28mself[39m._generate).parameters.get([33m"[39m[33mrun_manager[39m[33m"[39m):
[32m-> [39m[32m1192[39m     result = [38;5;28;43mself[39;49m[43m.[49m[43m_generate[49m[43m([49m
[32m   1193[39m [43m        [49m[43mmessages[49m[43m,[49m[43m [49m[43mstop[49m[43m=[49m[43mstop[49m[43m,[49m[43m [49m[43mrun_manager[49m[43m=[49m[43mrun_manager[49m[43m,[49m[43m [49m[43m*[49m[43m*[49m[43mkwargs[49m
[32m   1194[39m [43m    [49m[43m)[49m
[32m   1195[39m [38;5;28;01melse[39;00m:
[32m   1196[39m     result = [38;5;28mself[39m._generate(messages, stop=stop, **kwargs)

[36mFile [39m[32m~\OneDrive\Documents\AI\AgenticAi\venv\Lib\site-packages\langchain_groq\chat_models.py:544[39m, in [36mChatGroq._generate[39m[34m(self, messages, stop, run_manager, **kwargs)[39m
[32m    539[39m message_dicts, params = [38;5;28mself[39m._create_message_dicts(messages, stop)
[32m    540[39m params = {
[32m    541[39m     **params,
[32m    542[39m     **kwargs,
[32m    543[39m }
[32m--> [39m[32m544[39m response = [38;5;28;43mself[39;49m[43m.[49m[43mclient[49m[43m.[49m[43mcreate[49m[43m([49m[43mmessages[49m[43m=[49m[43mmessage_dicts[49m[43m,[49m[43m [49m[43m*[49m[43m*[49m[43mparams[49m[43m)[49m
[32m    545[39m [38;5;28;01mreturn[39;00m [38;5;28mself[39m._create_chat_result(response, params)

[36mFile [39m[32m~\OneDrive\Documents\AI\AgenticAi\venv\Lib\site-packages\groq\resources\chat\completions.py:464[39m, in [36mCompletions.create[39m[34m(self, messages, model, citation_options, compound_custom, disable_tool_validation, documents, exclude_domains, frequency_penalty, function_call, functions, include_domains, include_reasoning, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, n, parallel_tool_calls, presence_penalty, reasoning_effort, reasoning_format, response_format, search_settings, seed, service_tier, stop, store, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)[39m
[32m    244[39m [38;5;28;01mdef[39;00m[38;5;250m [39m[34mcreate[39m(
[32m    245[39m     [38;5;28mself[39m,
[32m    246[39m     *,
[32m   (...)[39m[32m    303[39m     timeout: [38;5;28mfloat[39m | httpx.Timeout | [38;5;28;01mNone[39;00m | NotGiven = not_given,
[32m    304[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:
[32m    305[39m [38;5;250m    [39m[33;03m"""[39;00m
[32m    306[39m [33;03m    Creates a model response for the given chat conversation.[39;00m
[32m    307[39m 
[32m   (...)[39m[32m    462[39m [33;03m      timeout: Override the client-level default timeout for this request, in seconds[39;00m
[32m    463[39m [33;03m    """[39;00m
[32m--> [39m[32m464[39m     [38;5;28;01mreturn[39;00m [38;5;28;43mself[39;49m[43m.[49m[43m_post[49m[43m([49m
[32m    465[39m [43m        [49m[33;43m"[39;49m[33;43m/openai/v1/chat/completions[39;49m[33;43m"[39;49m[43m,[49m
[32m    466[39m [43m        [49m[43mbody[49m[43m=[49m[43mmaybe_transform[49m[43m([49m
[32m    467[39m [43m            [49m[43m{[49m
[32m    468[39m [43m                [49m[33;43m"[39;49m[33;43mmessages[39;49m[33;43m"[39;49m[43m:[49m[43m [49m[43mmessages[49m[43m,[49m
[32m    469[39m [43m                [49m[33;43m"[39;49m[33;43mmodel[39;49m[33;43m"[39;49m[43m:[49m[43m [49m[43mmodel[49m[43m,[49m
[32m    470[39m [43m                [49m[33;43m"[39;49m[33;43mcitation_options[39;49m[33;43m"[39;49m[43m:[49m[43m [49m[43mcitation_options[49m[43m,[49m
[32m    471[39m [43m                [49m[33;43m"[39;49m[33;43mcompound_custom[39;49m[33;43m"[39;49m[43m:[49m[43m [49m[43mcompound_custom[49m[43m,[49m
[32m    472[39m [43m                [49m[33;43m"[39;49m[33;43mdisable_tool_validation[39;49m[33;43m"[39;49m[43m:[49m[43m [49m[43mdisable_tool_validation[49m[43m,[49m
[32m    473[39m [43m                [49m[33;43m"[39;49m[33;43mdocuments[39;49m[33;43m"[39;49m[43m:[49m[43m [49m[43mdocuments[49m[43m,[49m
[32m    474[39m [43m                [49m[33;43m"[39;49m[33;43mexclude_domains[39;49m[33;43m"[39;49m[43m:[49m[43m [49m[43mexclude_domains[49m[43m,[49m
[32m    475[39m [43m                [49m[33;43m"[39;49m[33;43mfrequency_penalty[39;49m[33;43m"[39;49m[43m:[49m[43m [49m[43mfrequency_penalty[49m[43m,[49m
[32m    476[39m [43m                [49m[33;43m"[39;49m[33;43mfunction_call[39;49m[33;43m"[39;49m[43m:[49m[43m [49m[43mfunction_call[49m[43m,[49m
[32m    477[39m [43m                [49m[33;43m"[39;49m[33;43mfunctions[39;49m[33;43m"[39;49m[43m:[49m[43m [49m[43mfunctions[49m[43m,[49m
[32m    478[39m [43m                [49m[33;43m"[39;49m[33;43minclude_domains[39;49m[33;43m"[39;49m[43m:[49m[43m [49m[43minclude_domains[49m[43m,[49m
[32m    479[39m [43m                [49m[33;43m"[39;49m[33;43minclude_reasoning[39;49m[33;43m"[39;49m[43m:[49m[43m [49m[43minclude_reasoning[49m[43m,[49m
[32m    480[39m [43m                [49m[33;43m"[39;49m[33;43mlogit_bias[39;49m[33;43m"[39;49m[43m:[49m[43m [49m[43mlogit_bias[49m[43m,[49m
[32m    481[39m [43m                [49m[33;43m"[39;49m[33;43mlogprobs[39;49m[33;43m"[39;49m[43m:[49m[43m [49m[43mlogprobs[49m[43m,[49m
[32m    482[39m [43m                [49m[33;43m"[39;49m[33;43mmax_completion_tokens[39;49m[33;43m"[39;49m[43m:[49m[43m [49m[43mmax_completion_tokens[49m[43m,[49m
[32m    483[39m [43m                [49m[33;43m"[39;49m[33;43mmax_tokens[39;49m[33;43m"[39;49m[43m:[49m[43m [49m[43mmax_tokens[49m[43m,[49m
[32m    484[39m [43m                [49m[33;43m"[39;49m[33;43mmetadata[39;49m[33;43m"[39;49m[43m:[49m[43m [49m[43mmetadata[49m[43m,[49m
[32m    485[39m [43m                [49m[33;43m"[39;49m[33;43mn[39;49m[33;43m"[39;49m[43m:[49m[43m [49m[43mn[49m[43m,[49m
[32m    486[39m [43m                [49m[33;43m"[39;49m[33;43mparallel_tool_calls[39;49m[33;43m"[39;49m[43m:[49m[43m [49m[43mparallel_tool_calls[49m[43m,[49m
[32m    487[39m [43m                [49m[33;43m"[39;49m[33;43mpresence_penalty[39;49m[33;43m"[39;49m[43m:[49m[43m [49m[43mpresence_penalty[49m[43m,[49m
[32m    488[39m [43m                [49m[33;43m"[39;49m[33;43mreasoning_effort[39;49m[33;43m"[39;49m[43m:[49m[43m [49m[43mreasoning_effort[49m[43m,[49m
[32m    489[39m [43m                [49m[33;43m"[39;49m[33;43mreasoning_format[39;49m[33;43m"[39;49m[43m:[49m[43m [49m[43mreasoning_format[49m[43m,[49m
[32m    490[39m [43m                [49m[33;43m"[39;49m[33;43mresponse_format[39;49m[33;43m"[39;49m[43m:[49m[43m [49m[43mresponse_format[49m[43m,[49m
[32m    491[39m [43m                [49m[33;43m"[39;49m[33;43msearch_settings[39;49m[33;43m"[39;49m[43m:[49m[43m [49m[43msearch_settings[49m[43m,[49m
[32m    492[39m [43m                [49m[33;43m"[39;49m[33;43mseed[39;49m[33;43m"[39;49m[43m:[49m[43m [49m[43mseed[49m[43m,[49m
[32m    493[39m [43m                [49m[33;43m"[39;49m[33;43mservice_tier[39;49m[33;43m"[39;49m[43m:[49m[43m [49m[43mservice_tier[49m[43m,[49m
[32m    494[39m [43m                [49m[33;43m"[39;49m[33;43mstop[39;49m[33;43m"[39;49m[43m:[49m[43m [49m[43mstop[49m[43m,[49m
[32m    495[39m [43m                [49m[33;43m"[39;49m[33;43mstore[39;49m[33;43m"[39;49m[43m:[49m[43m [49m[43mstore[49m[43m,[49m
[32m    496[39m [43m                [49m[33;43m"[39;49m[33;43mstream[39;49m[33;43m"[39;49m[43m:[49m[43m [49m[43mstream[49m[43m,[49m
[32m    497[39m [43m                [49m[33;43m"[39;49m[33;43mtemperature[39;49m[33;43m"[39;49m[43m:[49m[43m [49m[43mtemperature[49m[43m,[49m
[32m    498[39m [43m                [49m[33;43m"[39;49m[33;43mtool_choice[39;49m[33;43m"[39;49m[43m:[49m[43m [49m[43mtool_choice[49m[43m,[49m
[32m    499[39m [43m                [49m[33;43m"[39;49m[33;43mtools[39;49m[33;43m"[39;49m[43m:[49m[43m [49m[43mtools[49m[43m,[49m
[32m    500[39m [43m                [49m[33;43m"[39;49m[33;43mtop_logprobs[39;49m[33;43m"[39;49m[43m:[49m[43m [49m[43mtop_logprobs[49m[43m,[49m
[32m    501[39m [43m                [49m[33;43m"[39;49m[33;43mtop_p[39;49m[33;43m"[39;49m[43m:[49m[43m [49m[43mtop_p[49m[43m,[49m
[32m    502[39m [43m                [49m[33;43m"[39;49m[33;43muser[39;49m[33;43m"[39;49m[43m:[49m[43m [49m[43muser[49m[43m,[49m
[32m    503[39m [43m            [49m[43m}[49m[43m,[49m
[32m    504[39m [43m            [49m[43mcompletion_create_params[49m[43m.[49m[43mCompletionCreateParams[49m[43m,[49m
[32m    505[39m [43m        [49m[43m)[49m[43m,[49m
[32m    506[39m [43m        [49m[43moptions[49m[43m=[49m[43mmake_request_options[49m[43m([49m
[32m    507[39m [43m            [49m[43mextra_headers[49m[43m=[49m[43mextra_headers[49m[43m,[49m[43m [49m[43mextra_query[49m[43m=[49m[43mextra_query[49m[43m,[49m[43m [49m[43mextra_body[49m[43m=[49m[43mextra_body[49m[43m,[49m[43m [49m[43mtimeout[49m[43m=[49m[43mtimeout[49m
[32m    508[39m [43m        [49m[43m)[49m[43m,[49m
[32m    509[39m [43m        [49m[43mcast_to[49m[43m=[49m[43mChatCompletion[49m[43m,[49m
[32m    510[39m [43m        [49m[43mstream[49m[43m=[49m[43mstream[49m[43m [49m[38;5;129;43;01mor[39;49;00m[43m [49m[38;5;28;43;01mFalse[39;49;00m[43m,[49m
[32m    511[39m [43m        [49m[43mstream_cls[49m[43m=[49m[43mStream[49m[43m[[49m[43mChatCompletionChunk[49m[43m][49m[43m,[49m
[32m    512[39m [43m    [49m[43m)[49m

[36mFile [39m[32m~\OneDrive\Documents\AI\AgenticAi\venv\Lib\site-packages\groq\_base_client.py:1242[39m, in [36mSyncAPIClient.post[39m[34m(self, path, cast_to, body, options, files, stream, stream_cls)[39m
[32m   1228[39m [38;5;28;01mdef[39;00m[38;5;250m [39m[34mpost[39m(
[32m   1229[39m     [38;5;28mself[39m,
[32m   1230[39m     path: [38;5;28mstr[39m,
[32m   (...)[39m[32m   1237[39m     stream_cls: [38;5;28mtype[39m[_StreamT] | [38;5;28;01mNone[39;00m = [38;5;28;01mNone[39;00m,
[32m   1238[39m ) -> ResponseT | _StreamT:
[32m   1239[39m     opts = FinalRequestOptions.construct(
[32m   1240[39m         method=[33m"[39m[33mpost[39m[33m"[39m, url=path, json_data=body, files=to_httpx_files(files), **options
[32m   1241[39m     )
[32m-> [39m[32m1242[39m     [38;5;28;01mreturn[39;00m cast(ResponseT, [38;5;28;43mself[39;49m[43m.[49m[43mrequest[49m[43m([49m[43mcast_to[49m[43m,[49m[43m [49m[43mopts[49m[43m,[49m[43m [49m[43mstream[49m[43m=[49m[43mstream[49m[43m,[49m[43m [49m[43mstream_cls[49m[43m=[49m[43mstream_cls[49m[43m)[49m)

[36mFile [39m[32m~\OneDrive\Documents\AI\AgenticAi\venv\Lib\site-packages\groq\_base_client.py:1044[39m, in [36mSyncAPIClient.request[39m[34m(self, cast_to, options, stream, stream_cls)[39m
[32m   1041[39m             err.response.read()
[32m   1043[39m         log.debug([33m"[39m[33mRe-raising status error[39m[33m"[39m)
[32m-> [39m[32m1044[39m         [38;5;28;01mraise[39;00m [38;5;28mself[39m._make_status_error_from_response(err.response) [38;5;28;01mfrom[39;00m[38;5;250m [39m[38;5;28;01mNone[39;00m
[32m   1046[39m     [38;5;28;01mbreak[39;00m
[32m   1048[39m [38;5;28;01massert[39;00m response [38;5;129;01mis[39;00m [38;5;129;01mnot[39;00m [38;5;28;01mNone[39;00m, [33m"[39m[33mcould not resolve response (should never happen)[39m[33m"[39m

[31mRateLimitError[39m: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k47nkr5dendr4cprwwxzjy9v` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Used 7972, Requested 143. Please try again in 862.5ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
During task with name 'llm_call' and id '3bb26f27-653d-d2a8-ed64-4ffa53ba119c'

